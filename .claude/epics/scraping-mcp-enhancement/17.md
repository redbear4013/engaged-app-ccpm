# Task 005: Image Optimization Pipeline

## Metadata
```yaml
epic: scraping-mcp-enhancement
task_id: 005
title: Image Optimization Pipeline
status: pending
priority: medium
size: M
effort_hours: 8-10
parallel: true
depends_on: []
assignee: unassigned
created: 2025-10-01
updated: 2025-10-01
```

## Objective
Build an automated image processing pipeline that downloads event images, optimizes them through resizing and WebP conversion, stores them in Supabase Storage, and serves them via Cloudflare CDN with content-hash based deduplication.

## Scope

### In Scope
- ETag-aware image downloader with retry logic
- Multi-size image generation (thumbnail, medium, large)
- WebP conversion with quality optimization
- Supabase Storage integration with organized folder structure
- Cloudflare CDN configuration and cache purging
- Content-hash based deduplication
- Orphan image cleanup (events deleted but images remain)

### Out of Scope
- AI-powered image analysis/tagging
- Image editing/cropping tools
- User-uploaded image handling (separate flow)
- Video processing

## Technical Approach

### 1. Image Download Service
```typescript
// src/lib/images/downloader.ts
interface DownloadOptions {
  url: string;
  maxSizeBytes: number; // Reject oversized images
  timeout: number;
  retries: number;
  userAgent: string;
}

interface DownloadResult {
  buffer: Buffer;
  contentType: string;
  etag?: string;
  contentHash: string; // SHA-256 for dedup
  originalSize: number;
}

class ImageDownloader {
  async download(options: DownloadOptions): Promise<DownloadResult>;
  async batchDownload(urls: string[], concurrency: number): Promise<Map<string, DownloadResult>>;
}
```

**Features:**
- ETag tracking to avoid re-downloading unchanged images
- Conditional GET requests (If-None-Match header)
- Exponential backoff retry strategy
- MIME type validation (accept only image/jpeg, image/png, image/webp)
- Size limit enforcement (reject >5MB images)
- Connection pooling for batch downloads

### 2. Image Processing Pipeline
```typescript
// src/lib/images/processor.ts
interface ProcessingConfig {
  sizes: {
    thumbnail: { width: 320, height: 180, quality: 75 };
    medium: { width: 800, height: 450, quality: 85 };
    large: { width: 1920, height: 1080, quality: 90 };
  };
  format: 'webp';
  preserveAspectRatio: true;
  stripMetadata: true;
}

interface ProcessedImage {
  size: 'thumbnail' | 'medium' | 'large';
  buffer: Buffer;
  width: number;
  height: number;
  fileSize: number;
  contentHash: string;
}

class ImageProcessor {
  async processImage(
    input: Buffer,
    config: ProcessingConfig
  ): Promise<ProcessedImage[]>;
}
```

**Implementation:**
- Use `sharp` library for high-performance image processing
- Generate 3 size variants in parallel
- WebP conversion with quality presets
- Aspect ratio preservation with letterboxing if needed
- EXIF metadata stripping for privacy/size reduction
- Automatic color space conversion (sRGB)

**Size Strategy:**
- **Thumbnail (320×180)**: Grid/list views, lazy loading placeholder
- **Medium (800×450)**: Detail view on mobile/tablet
- **Large (1920×1080)**: Desktop detail view, hero images

### 3. Supabase Storage Integration
```typescript
// src/lib/images/storage.ts
interface StorageClient {
  uploadImage(
    eventId: string,
    image: ProcessedImage,
    metadata: ImageMetadata
  ): Promise<StorageUrl>;

  deleteImages(eventId: string): Promise<void>;

  getPublicUrl(path: string): string;

  listOrphanedImages(): Promise<string[]>;
}

interface ImageMetadata {
  originalUrl: string;
  contentHash: string;
  uploadedAt: Date;
  size: 'thumbnail' | 'medium' | 'large';
}
```

**Folder Structure:**
```
events/
  {event_id}/
    thumbnail.webp
    medium.webp
    large.webp

hashes/
  {content_hash}.webp  // Deduplicated original
```

**Storage Policies:**
- Public read access for `/events/**`
- Service role write access only
- Auto-delete on event deletion (cascading)
- 90-day retention for orphaned images before cleanup

### 4. Content-Hash Deduplication
```typescript
// src/lib/images/deduplication.ts
class ImageDeduplicator {
  async checkDuplicate(contentHash: string): Promise<string | null>;

  async linkDuplicate(
    eventId: string,
    existingHash: string
  ): Promise<void>;

  async getUsageCount(contentHash: string): Promise<number>;
}
```

**Deduplication Flow:**
1. Calculate SHA-256 hash of original image
2. Check if hash exists in `image_hashes` table
3. If exists: Create symbolic reference, skip upload
4. If new: Upload to `/hashes/{hash}.webp` + create entry
5. Generate size variants linked to hash

**Benefits:**
- Reduce storage costs by 40-60% (many events share images)
- Faster processing (skip duplicate conversions)
- Consistent images across events

### 5. Cloudflare CDN Integration
```typescript
// src/lib/images/cdn.ts
interface CDNConfig {
  zoneId: string;
  apiToken: string;
  cacheTtl: number;
  cacheKey: string; // Custom cache key rules
}

class CloudflareCDN {
  async purgeCache(urls: string[]): Promise<void>;

  async purgeAll(): Promise<void>;

  async getAnalytics(dateRange: DateRange): Promise<CDNMetrics>;
}
```

**Cloudflare Setup:**
- Transform Rules: Add WebP headers
- Cache Rules: Cache images for 30 days
- Polish: Auto-optimize images further
- Hotlink Protection: Prevent bandwidth theft
- Cache Purge API: Invalidate on image updates

**URL Pattern:**
```
https://cdn.engaged.app/events/{event_id}/{size}.webp
→ Cloudflare CDN
  → Supabase Storage public bucket
```

### 6. Database Schema
```sql
-- Image metadata tracking
CREATE TABLE event_images (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  event_id UUID REFERENCES events(id) ON DELETE CASCADE,
  content_hash TEXT NOT NULL,
  original_url TEXT NOT NULL,
  storage_path TEXT NOT NULL,
  size_variant TEXT CHECK (size_variant IN ('thumbnail', 'medium', 'large')),
  width INT NOT NULL,
  height INT NOT NULL,
  file_size_bytes INT NOT NULL,
  uploaded_at TIMESTAMPTZ DEFAULT NOW(),
  etag TEXT,
  UNIQUE(event_id, size_variant)
);

CREATE INDEX idx_images_event ON event_images(event_id);
CREATE INDEX idx_images_hash ON event_images(content_hash);

-- Deduplication tracking
CREATE TABLE image_hashes (
  content_hash TEXT PRIMARY KEY,
  original_storage_path TEXT NOT NULL,
  first_seen_url TEXT NOT NULL,
  usage_count INT DEFAULT 1,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  last_used_at TIMESTAMPTZ DEFAULT NOW()
);

-- Orphan cleanup tracking
CREATE TABLE orphaned_images (
  storage_path TEXT PRIMARY KEY,
  detected_at TIMESTAMPTZ DEFAULT NOW(),
  scheduled_deletion_at TIMESTAMPTZ DEFAULT NOW() + INTERVAL '90 days'
);
```

## Deliverables

### Code Artifacts
- [ ] `src/lib/images/downloader.ts` - ETag-aware download service
- [ ] `src/lib/images/processor.ts` - Sharp-based image processing
- [ ] `src/lib/images/storage.ts` - Supabase Storage client
- [ ] `src/lib/images/deduplication.ts` - Hash-based dedup
- [ ] `src/lib/images/cdn.ts` - Cloudflare CDN integration
- [ ] `src/lib/images/cleanup.ts` - Orphan image cleanup job

### Infrastructure
- [ ] Supabase Storage bucket: `event-images` (public)
- [ ] Cloudflare CDN zone configuration
- [ ] Cache purge webhook integration

### Database Migrations
- [ ] `migrations/012_event_images.sql`
- [ ] `migrations/013_image_hashes.sql`
- [ ] `migrations/014_orphaned_images.sql`

### Tests
- [ ] `downloader.test.ts` - ETag handling, retry logic
- [ ] `processor.test.ts` - Size variants, quality checks
- [ ] `storage.test.ts` - Upload/delete operations
- [ ] `deduplication.test.ts` - Hash collision handling
- [ ] `integration.test.ts` - End-to-end pipeline

### Documentation
- [ ] `docs/image-pipeline.md` - Architecture overview
- [ ] `docs/cdn-setup.md` - Cloudflare configuration guide
- [ ] `docs/storage-costs.md` - Cost analysis + optimization

## Acceptance Criteria

### Functional Requirements
- [ ] Download service handles 404, timeouts, and oversized images gracefully
- [ ] ETag caching reduces redundant downloads by 70%+
- [ ] All images converted to WebP with <10% quality loss
- [ ] Three size variants generated in <3s per image
- [ ] Deduplication reduces storage by 40%+ on real dataset
- [ ] CDN serves images with <100ms p95 latency
- [ ] Orphan cleanup removes unused images after 90 days

### Non-Functional Requirements
- [ ] Process 100 images concurrently without memory leaks
- [ ] Storage costs <$0.05 per 1000 images/month
- [ ] CDN bandwidth costs <$0.01 per 1000 requests
- [ ] Thumbnail generation <500ms p95
- [ ] Zero data loss on pipeline failures (retry + dead letter queue)

## Dependencies
- **Blocks**: None
- **Blocked By**: None (independent task)
- **Related**: Task 002 (Source Adapters) - provides image URLs

## Risks & Mitigation

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Sharp library version conflicts | Medium | Low | Pin version + Docker container |
| Supabase Storage rate limits | High | Medium | Batch uploads + exponential backoff |
| CDN cache poisoning | Medium | Low | Cache key versioning + purge API |
| Image copyright issues | High | Low | Respect robots.txt + source attribution |

## Timeline
- **Day 1**: Downloader + ETag handling
- **Day 2**: Image processor + WebP conversion
- **Day 3**: Supabase Storage integration
- **Day 4**: Deduplication logic
- **Day 5**: Cloudflare CDN setup
- **Day 6-7**: Integration testing + optimization
- **Day 8**: Orphan cleanup job + documentation

## Success Metrics
- **Storage Efficiency**: ≥40% reduction via deduplication
- **Performance**: <3s end-to-end processing per image
- **CDN Hit Rate**: ≥90% cache hit ratio
- **Cost**: <$10/month for 10k events with images
- **Reliability**: 99.9% successful processing rate
