# Task 006: Monitoring Dashboard & Alerting

## Metadata
```yaml
epic: scraping-mcp-enhancement
task_id: 006
title: Monitoring Dashboard & Alerting
status: pending
priority: high
size: L
effort_hours: 16-20
parallel: false
depends_on: [001, 002]
assignee: unassigned
created: 2025-10-01
updated: 2025-10-01
```

## Objective
Build a comprehensive admin monitoring dashboard with real-time metrics, per-source analytics, engine health visualization, and multi-channel alerting (Slack, email) for critical failures and performance degradation.

## Scope

### In Scope
- React-based admin dashboard with real-time metrics
- Per-source health sparklines and success rate tracking
- Scraping engine breakdown (Firecrawl, Playwright, fallback usage)
- Alert manager with configurable rules
- Slack webhook integration for instant notifications
- Email alerts via Resend for critical failures
- Manual scrape trigger UI for testing/debugging
- Historical metrics retention (30 days)

### Out of Scope
- User-facing analytics dashboard
- Advanced ML-based anomaly detection
- Custom metric builder (predefined metrics only)
- SMS alerting
- Grafana/Prometheus integration (future)

## Technical Approach

### 1. Metrics Collection System
```typescript
// src/lib/monitoring/metrics.ts
interface ScrapingMetrics {
  source_id: string;
  timestamp: Date;

  // Execution metrics
  jobs_started: number;
  jobs_completed: number;
  jobs_failed: number;
  avg_duration_ms: number;

  // Data quality metrics
  events_discovered: number;
  events_published: number;
  events_rejected: number;
  duplicate_rate: number;

  // Engine usage
  engine_breakdown: {
    firecrawl: number;
    playwright: number;
    fallback: number;
  };

  // Error tracking
  error_types: Record<string, number>;
  retry_count: number;
}

class MetricsCollector {
  async recordJobMetrics(jobId: string, metrics: Partial<ScrapingMetrics>): Promise<void>;

  async aggregateMetrics(
    timeRange: DateRange,
    groupBy: 'source' | 'engine' | 'hour'
  ): Promise<AggregatedMetrics>;

  async getRealtimeMetrics(): Promise<RealtimeSnapshot>;
}
```

**Collection Points:**
- Job start/completion/failure (orchestrator hooks)
- Event pipeline stages (discovered â†’ normalized â†’ published)
- Engine selection decisions (from orchestrator)
- Error handler (categorized by type)

**Aggregation Windows:**
- Real-time: Last 5 minutes (rolling)
- Hourly: Last 24 hours
- Daily: Last 30 days

### 2. Admin Dashboard UI
```typescript
// src/app/admin/monitoring/page.tsx
interface DashboardState {
  overview: {
    total_jobs_24h: number;
    success_rate: number;
    avg_events_per_job: number;
    active_sources: number;
  };

  sources: SourceMetrics[];
  engineBreakdown: EngineUsage;
  recentErrors: ErrorLog[];
  alerts: Alert[];
}

interface SourceMetrics {
  source_id: string;
  source_name: string;
  last_run: Date;
  success_rate_7d: number;
  sparkline_data: number[]; // Last 24 hourly runs
  status: 'healthy' | 'degraded' | 'failing';
  next_scheduled_run: Date;
}
```

**Dashboard Sections:**

**1. Overview Cards:**
- Total jobs (24h) with trend indicator (â†‘â†“)
- Overall success rate (7-day rolling average)
- Events discovered/published ratio
- Active vs paused sources

**2. Source Health Table:**
```tsx
<SourceHealthTable>
  {sources.map(source => (
    <SourceRow key={source.id}>
      <SourceName status={source.status}>{source.name}</SourceName>
      <Sparkline data={source.sparkline_data} />
      <SuccessRate value={source.success_rate_7d} />
      <LastRun timestamp={source.last_run} />
      <Actions>
        <ManualTrigger sourceId={source.id} />
        <ViewLogs sourceId={source.id} />
      </Actions>
    </SourceRow>
  ))}
</SourceHealthTable>
```

**3. Engine Breakdown Chart:**
- Donut chart showing engine usage distribution
- Tooltip with cost implications per engine
- Trend line (is Firecrawl usage increasing?)

**4. Recent Errors Panel:**
- Last 20 errors with timestamps
- Error type categorization (network, parsing, validation)
- Quick action: Retry failed job

**5. Active Alerts:**
- Unresolved alerts with severity badges
- Acknowledge/dismiss actions
- Alert history (last 7 days)

### 3. Alert Manager
```typescript
// src/lib/monitoring/alerts.ts
interface AlertRule {
  id: string;
  name: string;
  condition: AlertCondition;
  severity: 'info' | 'warning' | 'critical';
  channels: ('slack' | 'email')[];
  cooldown_minutes: number; // Prevent alert spam
  enabled: boolean;
}

interface AlertCondition {
  metric: keyof ScrapingMetrics;
  operator: 'gt' | 'lt' | 'eq';
  threshold: number;
  window_minutes: number; // Evaluate over time window
}

interface Alert {
  id: string;
  rule_id: string;
  triggered_at: Date;
  resolved_at?: Date;
  message: string;
  metadata: Record<string, any>;
}

class AlertManager {
  async evaluateRules(metrics: ScrapingMetrics): Promise<Alert[]>;

  async sendAlert(alert: Alert, channels: string[]): Promise<void>;

  async acknowledgeAlert(alertId: string, userId: string): Promise<void>;

  async getActiveAlerts(): Promise<Alert[]>;
}
```

**Predefined Alert Rules:**

| Rule | Condition | Severity | Channels |
|------|-----------|----------|----------|
| High failure rate | `success_rate < 50%` over 1h | Critical | Slack + Email |
| Source down | `jobs_failed >= 3` consecutive | Warning | Slack |
| No events discovered | `events_discovered == 0` for 24h | Warning | Email |
| Slow scraping | `avg_duration_ms > 60000` over 30min | Info | Slack |
| High duplicate rate | `duplicate_rate > 80%` over 1h | Info | Email |
| Engine fallback spike | `fallback_count > 10` in 1h | Warning | Slack |

**Cooldown Logic:**
- Prevent duplicate alerts within cooldown period
- Auto-resolve alerts when condition clears
- Escalation: If unresolved after 6h, upgrade severity

### 4. Slack Integration
```typescript
// src/lib/monitoring/notifications/slack.ts
interface SlackNotifier {
  sendAlert(alert: Alert): Promise<void>;

  sendJobSummary(summary: DailySummary): Promise<void>;

  sendTestMessage(): Promise<void>;
}

interface SlackMessage {
  blocks: Block[];
  attachments?: Attachment[];
}
```

**Alert Message Format:**
```json
{
  "blocks": [
    {
      "type": "header",
      "text": "ðŸš¨ Critical Alert: High Failure Rate"
    },
    {
      "type": "section",
      "text": "Source: Eventbrite API | Success Rate: 35% (threshold: 50%)",
      "fields": [
        { "type": "mrkdwn", "text": "*Failed Jobs:* 13/20" },
        { "type": "mrkdwn", "text": "*Time Window:* Last 1 hour" }
      ]
    },
    {
      "type": "actions",
      "elements": [
        {
          "type": "button",
          "text": "View Dashboard",
          "url": "https://admin.engaged.app/monitoring"
        },
        {
          "type": "button",
          "text": "Acknowledge",
          "action_id": "ack_alert_123"
        }
      ]
    }
  ]
}
```

**Daily Summary (8 AM):**
- Total jobs run
- Success rate vs yesterday
- Top 3 performing sources
- Top 3 issues

### 5. Email Alerts
```typescript
// src/lib/monitoring/notifications/email.ts
interface EmailNotifier {
  sendCriticalAlert(alert: Alert, recipients: string[]): Promise<void>;

  sendWeeklySummary(summary: WeeklySummary, recipients: string[]): Promise<void>;
}
```

**Email Template (Resend + React Email):**
```tsx
// emails/critical-alert.tsx
export function CriticalAlertEmail({ alert }: { alert: Alert }) {
  return (
    <Html>
      <Head />
      <Preview>Critical Alert: {alert.rule_name}</Preview>
      <Body>
        <Container>
          <Heading>ðŸš¨ Critical Alert Triggered</Heading>
          <Text><strong>Rule:</strong> {alert.rule_name}</Text>
          <Text><strong>Source:</strong> {alert.source_name}</Text>
          <Text><strong>Details:</strong> {alert.message}</Text>
          <Button href="https://admin.engaged.app/monitoring">
            View Dashboard
          </Button>
        </Container>
      </Body>
    </Html>
  );
}
```

**Recipients:**
- Critical: Admin + on-call engineer
- Warning: Admin only
- Info: Logged only (no email)

### 6. Manual Trigger UI
```typescript
// src/app/admin/monitoring/components/ManualTrigger.tsx
interface ManualTriggerProps {
  sourceId: string;
}

function ManualTrigger({ sourceId }: ManualTriggerProps) {
  const [loading, setLoading] = useState(false);

  const handleTrigger = async () => {
    setLoading(true);
    try {
      await fetch('/api/admin/scraping/trigger', {
        method: 'POST',
        body: JSON.stringify({ source_id: sourceId })
      });
      toast.success('Scraping job triggered');
    } catch (error) {
      toast.error('Failed to trigger job');
    } finally {
      setLoading(false);
    }
  };

  return (
    <Button onClick={handleTrigger} loading={loading}>
      Trigger Now
    </Button>
  );
}
```

**Trigger Endpoint:**
```typescript
// src/app/api/admin/scraping/trigger/route.ts
export async function POST(request: Request) {
  const { source_id } = await request.json();

  // Admin auth check
  const session = await getServerSession();
  if (!session?.user?.isAdmin) {
    return Response.json({ error: 'Unauthorized' }, { status: 403 });
  }

  // Enqueue job with priority flag
  await orchestrator.enqueueJob({
    source_id,
    priority: 'high',
    triggered_by: 'manual',
    user_id: session.user.id
  });

  return Response.json({ success: true });
}
```

### 7. Database Schema
```sql
-- Metrics storage (30-day retention)
CREATE TABLE scraping_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_id UUID REFERENCES scraping_sources(id),
  recorded_at TIMESTAMPTZ DEFAULT NOW(),

  jobs_started INT DEFAULT 0,
  jobs_completed INT DEFAULT 0,
  jobs_failed INT DEFAULT 0,
  avg_duration_ms INT,

  events_discovered INT DEFAULT 0,
  events_published INT DEFAULT 0,
  events_rejected INT DEFAULT 0,
  duplicate_rate DECIMAL(5,2),

  engine_breakdown JSONB,
  error_types JSONB,
  retry_count INT DEFAULT 0
);

CREATE INDEX idx_metrics_source_time ON scraping_metrics(source_id, recorded_at DESC);
CREATE INDEX idx_metrics_time ON scraping_metrics(recorded_at DESC);

-- Auto-delete old metrics
CREATE OR REPLACE FUNCTION delete_old_metrics()
RETURNS void AS $$
BEGIN
  DELETE FROM scraping_metrics
  WHERE recorded_at < NOW() - INTERVAL '30 days';
END;
$$ LANGUAGE plpgsql;

-- Alert rules configuration
CREATE TABLE alert_rules (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT NOT NULL,
  condition JSONB NOT NULL,
  severity TEXT CHECK (severity IN ('info', 'warning', 'critical')),
  channels TEXT[] DEFAULT '{}',
  cooldown_minutes INT DEFAULT 60,
  enabled BOOLEAN DEFAULT true,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Active alerts
CREATE TABLE alerts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_id UUID REFERENCES alert_rules(id),
  source_id UUID REFERENCES scraping_sources(id),
  triggered_at TIMESTAMPTZ DEFAULT NOW(),
  resolved_at TIMESTAMPTZ,
  acknowledged_by UUID REFERENCES admin_users(id),
  message TEXT NOT NULL,
  metadata JSONB
);

CREATE INDEX idx_alerts_active ON alerts(triggered_at DESC)
  WHERE resolved_at IS NULL;
```

## Deliverables

### Code Artifacts
- [ ] `src/lib/monitoring/metrics.ts` - Metrics collection service
- [ ] `src/lib/monitoring/alerts.ts` - Alert evaluation engine
- [ ] `src/lib/monitoring/notifications/slack.ts` - Slack integration
- [ ] `src/lib/monitoring/notifications/email.ts` - Email notifications
- [ ] `src/app/admin/monitoring/page.tsx` - Dashboard UI
- [ ] `src/app/admin/monitoring/components/` - Dashboard components
  - `SourceHealthTable.tsx`
  - `EngineBreakdown.tsx`
  - `AlertsPanel.tsx`
  - `ManualTrigger.tsx`
- [ ] `src/app/api/admin/scraping/trigger/route.ts` - Manual trigger API

### Database Migrations
- [ ] `migrations/015_scraping_metrics.sql`
- [ ] `migrations/016_alert_rules.sql`
- [ ] `migrations/017_alerts.sql`

### Infrastructure
- [ ] Slack webhook URL configuration
- [ ] Resend email sender domain verification
- [ ] Cron job: Daily metrics aggregation
- [ ] Cron job: Old metrics cleanup (30-day retention)

### Tests
- [ ] `metrics.test.ts` - Aggregation logic correctness
- [ ] `alerts.test.ts` - Rule evaluation + cooldown
- [ ] `slack-notifier.test.ts` - Message formatting
- [ ] `email-notifier.test.ts` - Template rendering
- [ ] `dashboard.test.tsx` - UI component rendering

### Documentation
- [ ] `docs/monitoring-guide.md` - Dashboard user guide
- [ ] `docs/alert-rules.md` - Alert configuration reference
- [ ] `docs/troubleshooting.md` - Common issues + solutions

## Acceptance Criteria

### Functional Requirements
- [ ] Dashboard loads in <2s with 30 days of metrics
- [ ] Real-time metrics update every 30s without full page reload
- [ ] Sparklines render 24 hourly data points per source
- [ ] Alerts trigger within 5 minutes of threshold breach
- [ ] Slack messages formatted correctly with action buttons
- [ ] Email alerts delivered within 2 minutes
- [ ] Manual trigger executes job immediately (no schedule delay)
- [ ] Alert cooldown prevents spam (max 1 per hour per rule)

### Non-Functional Requirements
- [ ] Dashboard supports 50+ sources without performance degradation
- [ ] Metrics storage <100MB for 30 days with 20 sources
- [ ] Alert evaluation runs in <1s
- [ ] UI responsive on mobile/tablet
- [ ] 99.9% notification delivery rate

## Dependencies
- **Blocks**: None
- **Blocked By**:
  - Task 001 (Orchestrator) - needs job execution hooks
  - Task 002 (Source Adapters) - needs per-source metrics
- **Related**:
  - Task 004 (Data Quality) - quality metrics integration
  - Task 005 (Image Pipeline) - image processing metrics

## Risks & Mitigation

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Slack rate limits on high alert volume | Medium | Medium | Batching + cooldown enforcement |
| Email deliverability issues | High | Low | Use Resend with verified domain |
| Metrics storage growth | Medium | Medium | 30-day auto-cleanup + aggregation |
| Alert fatigue from false positives | High | Medium | Tunable thresholds + cooldown |

## Timeline
- **Day 1-2**: Metrics collection system + database schema
- **Day 3-4**: Alert evaluation engine + rules configuration
- **Day 5-6**: Slack integration + message templates
- **Day 7**: Email notifications via Resend
- **Day 8-10**: Dashboard UI (overview, source table, charts)
- **Day 11**: Manual trigger UI + API endpoint
- **Day 12-13**: Integration testing + real data validation
- **Day 14**: Documentation + admin training

## Success Metrics
- **Visibility**: 100% of scraping jobs tracked with metrics
- **Alerting**: <5 min mean time to alert (MTTA)
- **Response**: <30 min mean time to acknowledge (MTTA)
- **Reliability**: 99.9% alert delivery success rate
- **Usability**: Admins resolve 80%+ issues without engineering support
